# -*- coding: utf-8 -*-
"""Sistem Rekomendasi Karir_item translated.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vxl-VpDz5cuc55CGfUscu78G4u3UVtD9


"""# Data Pre-Processing User"""

import pandas as pd
import numpy as np
import plotly.graph_objects as go
import openpyxl
import json

df = pd.read_excel('dataset_user.xlsx')

df.head(2)

df[['IPK','Pengelolaan informasi pembelajaran','Pengelolaan situasi yang dihadapi','Kreativitas dalam bersikap','Pola Komunikasi','Interaksi dengan lingkungan pembelajaran','Minat Karir dan Kesesuaian potensi bidang pekerjaan','Saran Pengembangan Diri 1', 'Saran Pengembangan Diri 2','Saran Pengembangan Diri 3','Saran Pengembangan Diri 4']]

df.info()

df['IPK'].unique()

df['IPK'] = np.where(df["IPK"] == 'Mengundurkan Diri', 0, df['IPK'])

df['IPK'].unique()

IPK_mean = df['IPK'].mean()
IPK_mean = np.round(IPK_mean, decimals = 2)
IPK_mean

df['IPK'] = np.where(df["IPK"] == 0, IPK_mean, df['IPK'])

df['IPK'].unique()

df['Saran Pengembangan Diri 4']

df.head(10)

df['Pengelolaan informasi pembelajaran'] = df['Pengelolaan informasi pembelajaran'].str.lower()
df['Pengelolaan situasi yang dihadapi'] = (df['Pengelolaan situasi yang dihadapi']
                                           .str.lower()
                                           .str.replace("influence ", "influence", regex= True))
df['Interaksi dengan lingkungan pembelajaran'] = df['Interaksi dengan lingkungan pembelajaran'].str.lower()
df['Pengambilan Keputusan dan Kepemimpinan '] = df['Pengambilan Keputusan dan Kepemimpinan '].str.lower()
df['Minat Karir dan Kesesuaian potensi bidang pekerjaan'] = (df['Minat Karir dan Kesesuaian potensi bidang pekerjaan']
                                                             .str.lower()
                                                             .str.replace("birokrat ","birokrat", regex=True)
                                                             .str.replace("entrepreneur","enterpreneur", regex=True))

df['Kreativitas dalam bersikap'] = (df['Kreativitas dalam bersikap']
                                    .str.lower()
                                    .str.replace("[^a-zA-Z\s]", "", regex=True)
                                    .str.replace("\s+", " ", regex=True)
                                    .str.replace("\ $", "", regex=True)
                                    .str.replace("\\n\n$", "", regex=True))
df['Pola Komunikasi'] = (df['Pola Komunikasi']
                         .str.lower()
                         .str.replace("[^a-zA-Z\s]", "", regex=True)
                         .str.replace("\n", "", regex=True)
                         .str.replace("\s+", " ", regex=True)
                         .str.replace("\ $", "", regex=True)
                         .str.replace("\\n\n$", "", regex=True))
df['Saran Pengembangan Diri 1'] = (df['Saran Pengembangan Diri 1']
                                   .str.lower()
                                   .str.replace("[^a-zA-Z\s]", "", regex=True)
                                   .str.replace("\s+", " ", regex=True)
                                   .str.replace("^ ", "", regex=True)
                                   .str.replace("\ $", "", regex=True)
                                   .str.replace("\\n\n$", "", regex=True))
df['Saran Pengembangan Diri 2'] = (df['Saran Pengembangan Diri 2']
                                   .str.lower()
                                   .str.replace("[^a-zA-Z\s]", "", regex=True)
                                   .str.replace("\s+", " ", regex=True)
                                   .str.replace("^ ", "", regex=True)
                                   .str.replace("\ $", "", regex=True)
                                   .str.replace("\\n\n$", "", regex=True))
df['Saran Pengembangan Diri 3'] = (df['Saran Pengembangan Diri 3']
                                     .str.lower()
                                     .str.replace("[^a-zA-Z\s]", "", regex=True)
                                     .str.replace("\s+", " ", regex=True)
                                     .str.replace("^ ", "", regex=True)
                                     .str.replace("\ $", "", regex=True)
                                     .str.replace("\\n\n$", "", regex=True))
df['Saran Pengembangan Diri 4'] = (df['Saran Pengembangan Diri 4']
                                   .str.lower()
                                   .str.replace("[^a-zA-Z\s]", "", regex=True)
                                   .str.replace("\s+", " ", regex=True)
                                   .str.replace("^ ", "", regex=True)
                                   .str.replace("\ $", "", regex=True)
                                   .str.replace("\\n\n$", "", regex=True))

df['Pengelolaan informasi pembelajaran'].unique()

df['Pengelolaan situasi yang dihadapi'].unique()

df['Kreativitas dalam bersikap'].unique()

df['Pola Komunikasi'].unique()

df['Interaksi dengan lingkungan pembelajaran'].unique()

df['Pengambilan Keputusan dan Kepemimpinan '].unique()

df['Minat Karir dan Kesesuaian potensi bidang pekerjaan'].unique()

df['Saran Pengembangan Diri 1'].unique()

df['Saran Pengembangan Diri 2'].unique()

df['Saran Pengembangan Diri 3'].unique()

df['Saran Pengembangan Diri 4'].unique()

file_path = 'stopwords-id.txt'

with open(file_path, 'r') as file:
    stop_words_id = file.read().split('\n')
    stop_words_id = [word for word in stop_words_id if word]
    print(stop_words_id[:10])

def remove_stopwords(text):
    words = text.split()
    clean_words = [word for word in words if word not in stop_words_id]
    return ' '.join(clean_words)

df['Interaksi dengan lingkungan pembelajaran'] = df['Interaksi dengan lingkungan pembelajaran'].apply(remove_stopwords)
df['Pengelolaan informasi pembelajaran'] = df['Pengelolaan informasi pembelajaran'].apply(remove_stopwords)
df['Pengelolaan situasi yang dihadapi'] = df['Pengelolaan situasi yang dihadapi'].apply(remove_stopwords)
df['Pengambilan Keputusan dan Kepemimpinan '] = df['Pengambilan Keputusan dan Kepemimpinan '].apply(remove_stopwords)
df['Minat Karir dan Kesesuaian potensi bidang pekerjaan'] = df['Minat Karir dan Kesesuaian potensi bidang pekerjaan'].apply(remove_stopwords)
df['Kreativitas dalam bersikap'] = df['Kreativitas dalam bersikap'].apply(remove_stopwords)
df['Pola Komunikasi'] = df['Pola Komunikasi'].apply(remove_stopwords)
df['Saran Pengembangan Diri 1'] = df['Saran Pengembangan Diri 1'].apply(remove_stopwords)
df['Saran Pengembangan Diri 2'] = df['Saran Pengembangan Diri 2'].apply(remove_stopwords)
df['Saran Pengembangan Diri 3'] = df['Saran Pengembangan Diri 3'].apply(remove_stopwords)
df['Saran Pengembangan Diri 4'] = df['Saran Pengembangan Diri 4'].apply(remove_stopwords)

print(df['Saran Pengembangan Diri 2'].head(5))

df.head(5)

df.info()

df = df.drop(['Unnamed: 0', 'IPK', 'Departemen'], axis=1)

df.head(10)

df.info()

"""#Data Pre-Processing Item"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import re

item_df = pd.read_csv('training_data_cleaned_translated.csv')
#item_df.head()
item_df.info()

item_df

len(item_df['position_title'].unique())

"""# Content Based Filtering

## Ekstrasi Fitur User
"""

from sklearn.feature_extraction.text import TfidfVectorizer

# Gabungkan teks dari kolom yang relevan
df['text_combined'] = df[['Pengelolaan informasi pembelajaran', 'Pengelolaan situasi yang dihadapi', 'Kreativitas dalam bersikap', 'Pola Komunikasi', 'Interaksi dengan lingkungan pembelajaran', 'Pengambilan Keputusan dan Kepemimpinan ','Minat Karir dan Kesesuaian potensi bidang pekerjaan', 'Saran Pengembangan Diri 1', 'Saran Pengembangan Diri 2', 'Saran Pengembangan Diri 3', 'Saran Pengembangan Diri 4']].apply(lambda row: ' '.join(row.values.astype(str)), axis=1)

# Inisialisasi TfidfVectorizer dengan stop words Indonesia
tfidf = TfidfVectorizer()

# Terapkan TF-IDF pada teks gabungan
tfidf_matrix_user = tfidf.fit_transform(df['text_combined'])

df['text_combined'].head()

"""## Ekstrasi Fitur Item"""

item_df['item_combined'] = item_df[['position_title', 'Core Responsibilities', 'Required Skill']].apply(lambda row: ' '.join(row.values.astype(str)), axis=1)

# Terapkan TF-IDF pada teks gabungan
tfidf_matrix_item = tfidf.transform(item_df['item_combined'])

print(tfidf_matrix_user)

from scipy.sparse import find
# Mencari elemen dengan nilai di atas 0.5
# Fungsi 'find' dari scipy.sparse akan mengembalikan baris, kolom, dan nilai dari elemen non-zero

rows, cols, values = find(tfidf_matrix_user)

# Menyaring dan menampilkan hanya yang nilainya > 0.5
for row, col, value in zip(rows, cols, values):
    if value > 0.5:
        print(f"Baris: {row}, Kolom: {col}, Nilai: {value}")

print(tfidf_matrix_item)

from scipy.sparse import find
# Mencari elemen dengan nilai di atas 0.5
# Fungsi 'find' dari scipy.sparse akan mengembalikan baris, kolom, dan nilai dari elemen non-zero

rows, cols, values = find(tfidf_matrix_item)

# Menyaring dan menampilkan hanya yang nilainya > 0.5
for row, col, value in zip(rows, cols, values):
    if value > 0.5:
        print(f"Baris: {row}, Kolom: {col}, Nilai: {value}")

"""## Kesamaan Kosinus"""

tfidf_matrix_user.shape

tfidf_matrix_item.shape

from sklearn.metrics.pairwise import cosine_similarity

cos_sim = cosine_similarity(tfidf_matrix_user, tfidf_matrix_item)

# Mendapatkan ranking item berdasarkan skor kesamaan
item_ranking = np.argsort(cos_sim[1])[::-1]

# Menampilkan rekomendasi top 3
top_3_items = item_df['position_title'].iloc[item_ranking[:10]]
print(top_3_items)

# Mendapatkan skor kesamaan untuk pengguna dengan indeks 1
user_similarity_scores = cos_sim[1]

# Mencetak semua skor kesamaan untuk pengguna tersebut
print(user_similarity_scores)

"""# -------------------------------------------------------------------------------------------------------

## Data Input User

Menyesuaikan Matriks Setelah Perhitungan:
Jika Anda sudah memiliki dua matriks TF-IDF yang berbeda, Anda bisa menggunakan teknik seperti pemotongan (trimming) atau penambahan fitur (padding) untuk menyelaraskan jumlah fitur. Biasanya lebih mudah untuk menghindari perbedaan ini dari awal dengan menggunakan pendekatan pertama.Contoh pemotongan:
"""

def user_preprocessing(df_new):
      # Pastikan semua kolom yang perlu diubah menjadi huruf kecil dan lakukan cleaning teks
    file_path = 'stopwords-id.txt'

    with open(file_path, 'r') as file:
      stop_words_id = file.read().split('\n')
      stop_words_id = [word for word in stop_words_id if word]
      print(stop_words_id[:10])

    def remove_stopwords(text):
      words = text.split()
      clean_words = [word for word in words if word not in stop_words_id]
      return ' '.join(clean_words)
    
    columns_to_clean = ['Pengelolaan informasi pembelajaran', 'Pengelolaan situasi yang dihadapi',
                        'Kreativitas dalam bersikap', 'Pola Komunikasi', 'Interaksi dengan lingkungan pembelajaran',
                        'Pengambilan Keputusan dan Kepemimpinan', 'Minat Karir dan Kesesuaian potensi bidang pekerjaan',
                        'Saran Pengembangan Diri 1', 'Saran Pengembangan Diri 2', 'Saran Pengembangan Diri 3',
                        'Saran Pengembangan Diri 4']

    for column in columns_to_clean:
        df_new[column] = df_new[column].str.lower().str.replace("[^a-zA-Z\s]", "").str.replace("\s+", " ", regex=True).str.strip()
        df_new[column] = df_new[column].apply(remove_stopwords)
    return df_new

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

def tfidf_new(df_cleaned_new, item_df):
  ######################################## buat USER TF-IDF
  # Gabungkan teks dari kolom yang relevan
  df_cleaned_new['text_combined'] = df_cleaned_new[['Pengelolaan informasi pembelajaran', 'Pengelolaan situasi yang dihadapi', 'Kreativitas dalam bersikap', 'Pola Komunikasi', 'Interaksi dengan lingkungan pembelajaran', 'Pengambilan Keputusan dan Kepemimpinan','Minat Karir dan Kesesuaian potensi bidang pekerjaan', 'Saran Pengembangan Diri 1', 'Saran Pengembangan Diri 2', 'Saran Pengembangan Diri 3', 'Saran Pengembangan Diri 4']].apply(lambda row: ' '.join(row.values.astype(str)), axis=1)

  # Inisialisasi TfidfVectorizer dengan stop words Indonesia
  tfidf_model = TfidfVectorizer()

  # Terapkan TF-IDF pada teks gabungan
  tfidf_matrix_user_new = tfidf_model.fit_transform(df_cleaned_new['text_combined'])

  ######################################## buat ITEM TF-IDF
  item_df['item_combined'] = item_df[['position_title', 'Core Responsibilities', 'Required Skill']].apply(lambda row: ' '.join(row.values.astype(str)), axis=1)

  # Terapkan TF-IDF pada teks gabungan
  tfidf_matrix_item_new = tfidf_model.transform(item_df['item_combined'])

  print(tfidf_matrix_item_new.shape, tfidf_matrix_user_new.shape)

  ######################################## buat Similarity score
  global cos_sim_new
  cos_sim_new = cosine_similarity(tfidf_matrix_user_new, tfidf_matrix_item_new)

  # Mengagregasi rekomendasi berdasarkan skor kesamaan dari pengguna lain
  global aggregated_recommendations
  # Menghitung rata-rata dari `cos_sim`
  cos_sim_mean = np.mean(cos_sim, axis=0)

  # Menggabungkan rata-rata `cos_sim` dengan `cos_sim_new` dan menghitung rata-rata akhir
  aggregated_recommendations = (cos_sim_mean + cos_sim_new) / 2

  # Pilih rekomendasi top berdasarkan agregasi skor kesamaan
  item_ranking_aggregated = np.argsort(aggregated_recommendations, axis=1)[:, ::-1]
  return item_ranking_aggregated, item_df

def result(item_ranking_aggregated, item_df):
  global top_3_items_aggregated
  top_3_items_indices_aggregated = item_ranking_aggregated[0, :3]
  top_3_items_aggregated = item_df['position_title'].iloc[top_3_items_indices_aggregated]
  top_3_items_agg_desc = item_df['Deskripsi'].iloc[top_3_items_indices_aggregated]

  # Membuat DataFrame untuk menyimpan rekomendasi top 3 beserta label urutan
  top_3_df_aggregated = pd.DataFrame({'Urutan': ['1', '2', '3'], 'Top Rekomendasi (Agregasi Pengguna Lain)': top_3_items_aggregated.values, 'Deskripsi': top_3_items_agg_desc})
  
  return top_3_df_aggregated

def get_user_input(df_new):

  # data1 = input("Masukkan pengelolaan informasi pembelajaran: ")
  # data2 = input("Masukkan pengelolaan situasi yang dihadapi: ")
  # data3 = input("Masukkan kreativitas dalam bersikap: ")
  # data4 = input("Masukkan pola komunikasi: ")
  # data5 = input("Masukkan interaksi dengan lingkungan pembelajaran: ")
  # data6 = input("Masukkan Pengambilan Keputusan dan Kepemimpinan: ")
  # data7 = input("Masukkan minat karir dan kesesuaian potensi bidang pekerjaan: ")
  # data8 = input("Masukkan saran pengembangan diri 1: ")
  # data9 = input("Masukkan saran pengembangan diri 2: ")
  # data10 = input("Masukkan saran pengembangan diri 3: ")
  # data11 = input("Masukkan saran pengembangan diri 4: ")

  df_new_cleaned = user_preprocessing(df_new) # memanggil fungsi cleaning
  return df_new_cleaned
# get_user_input()

# print(cos_sim_new[0])


